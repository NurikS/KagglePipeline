{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to clean the dataset from the unnecesarry instances and remove the outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import Imputer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"Data/train.csv\"\n",
    "TEST_PATH = \"Data/test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# choose from the EDA \n",
    "columns_to_drop = [\"PoolQC\", \"Fence\", \"MiscFeature\", \"FireplaceQu\", \"Alley\"]\n",
    "\n",
    "#handle missing values\n",
    "def missing_values(dataframe):\n",
    "    # drop some columns that have too few values\n",
    "    dataframe.drop(columns = columns_to_drop)\n",
    "    #Impute values into other columns with missing values, what we need is the sound strategy\n",
    "    #I could either use the mean values for everything, for categories i suppose we would use mode.\n",
    "    #Let's handle missing values in the features that show high correlation\n",
    "    dataframe[\"LotFrontage\"] = dataframe[[\"LotFrontage\"]].fillna(dataframe[[\"LotFrontage\"]].mean()[0])\n",
    "    dataframe[\"MasVnrArea\"] = dataframe[[\"MasVnrArea\"]].fillna(dataframe[[\"MasVnrArea\"]].mean()[0])\n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "\n",
    "#handle outliers\n",
    "def outliers(dataframe):\n",
    "    #seems like outlier handling also depends on specific features (obviously), so let's see from the scatter plots\n",
    "    #where in the high correlating features, we have outliers.\n",
    "    dataframe.drop(dataframe[(dataframe['OverallQual']<5) & (dataframe['SalePrice']>200000)].index, inplace=True)\n",
    "    dataframe.drop(dataframe[(dataframe['GrLivArea']>4500) & (dataframe['SalePrice']<300000)].index, inplace=True)\n",
    "    dataframe.reset_index(drop=True, inplace=True)\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = missing_values(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = outliers(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv(\"CleanTrainData.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
